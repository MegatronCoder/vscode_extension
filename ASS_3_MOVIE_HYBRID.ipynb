{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a73b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Real Data ---\n",
      "Loaded 27278 movies.\n",
      "Loaded a sample of 10000 ratings (up to 5000000).\n",
      "\n",
      "--- 2. Applying Filtering Logic ---\n",
      "Ratings after (movie >= 50): 5379\n",
      "Ratings after (user >= 20): 4136\n",
      "Applying rating cap (this may take a moment)...\n",
      "Ratings after (movie <= 70): 3724\n",
      "\n",
      "Final movies in system: 68\n",
      "Final ratings in system: 3724\n",
      "Final users in system: 143\n",
      "\n",
      "--- 3. Building Content-Based Filter (TF-IDF) ---\n",
      "Content filter built.\n",
      "\n",
      "--- 4. Building Collaborative Ranker (sklearn TruncatedSVD) ---\n",
      "Training TruncatedSVD model...\n",
      "SVD model trained.\n",
      "Collaborative ranker built.\n",
      "\n",
      "--- 5. Getting Hybrid Recommendations ---\n",
      "\n",
      "Target User: 99851, Target Movie: Toy Story (1995)\n",
      "\n",
      "Top 10 Hybrid Recommendations:\n",
      "1. Englishman Who Went Up a Hill But Came Down a Mountain, The (1995)\n",
      "2. Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "3. Seven (a.k.a. Se7en) (1995)\n",
      "4. Dangerous Minds (1995)\n",
      "5. Madness of King George, The (1994)\n",
      "6. Clueless (1995)\n",
      "7. Ed Wood (1994)\n",
      "8. French Kiss (1995)\n",
      "9. Rob Roy (1995)\n",
      "10. Get Shorty (1995)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13562/4079590526.py:110: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ratings_f3 = ratings_f2.groupby('movieId').apply(cap_movie_ratings).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "import sys\n",
    "\n",
    "MIN_MOVIE_RATINGS = 50\n",
    "MAX_MOVIE_RATINGS = 70\n",
    "MIN_USER_RATINGS = 20\n",
    "RATINGS_SAMPLE_SIZE = 5000000\n",
    "\n",
    "def cap_movie_ratings(group):\n",
    "    if len(group) > MAX_MOVIE_RATINGS:\n",
    "        return group.sample(n=MAX_MOVIE_RATINGS, random_state=1)\n",
    "    return group\n",
    "\n",
    "def get_content_filter(movies_df):\n",
    "    movies_df_copy = movies_df.copy()\n",
    "    movies_df_copy['genres_processed'] = movies_df_copy['genres'].fillna(\"\").str.replace('|', ' ')\n",
    "    \n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(movies_df_copy['genres_processed'])\n",
    "    \n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    movies_df_copy = movies_df_copy.reset_index()\n",
    "    indices = pd.Series(movies_df_copy.index, index=movies_df_copy['title']).drop_duplicates()\n",
    "    \n",
    "    return cosine_sim, indices, movies_df_copy\n",
    "\n",
    "def get_collaborative_filter(ratings_df):\n",
    "    user_ids = ratings_df['userId'].unique()\n",
    "    movie_ids = ratings_df['movieId'].unique()\n",
    "    \n",
    "    user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "    movie_id_to_index = {movie_id: index for index, movie_id in enumerate(movie_ids)}\n",
    "    \n",
    "    ratings_df_copy = ratings_df.copy()\n",
    "    ratings_df_copy['user_index'] = ratings_df_copy['userId'].map(user_id_to_index)\n",
    "    ratings_df_copy['movie_index'] = ratings_df_copy['movieId'].map(movie_id_to_index)\n",
    "    \n",
    "    n_users = len(user_ids)\n",
    "    n_movies = len(movie_ids)\n",
    "    \n",
    "    user_item_matrix = csr_matrix(\n",
    "        (ratings_df_copy['rating'], (ratings_df_copy['user_index'], ratings_df_copy['movie_index'])),\n",
    "        shape=(n_users, n_movies)\n",
    "    )\n",
    "\n",
    "    print(\"Training TruncatedSVD model...\")\n",
    "    svd_model = TruncatedSVD(n_components=50, random_state=42) \n",
    "    user_factors = svd_model.fit_transform(user_item_matrix)\n",
    "    item_factors = svd_model.components_.T\n",
    "    print(\"SVD model trained.\")\n",
    "\n",
    "    return svd_model, user_factors, item_factors, user_id_to_index, movie_id_to_index, user_ids.tolist()\n",
    "\n",
    "def get_hybrid_recommendations(user_id, movie_title, movies_df, content_indices, content_cosine_sim, cf_model, user_factors, item_factors, user_map, movie_map):\n",
    "    \n",
    "    content_idx = content_indices[movie_title]\n",
    "    sim_scores = list(enumerate(content_cosine_sim[content_idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:51]\n",
    "    content_movie_indices = [i[0] for i in sim_scores]\n",
    "    candidates_df = movies_df.iloc[content_movie_indices][['title', 'movieId']]\n",
    "\n",
    "    user_matrix_index = user_map[user_id]\n",
    "    user_vec = user_factors[user_matrix_index]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for _, row in candidates_df.iterrows():\n",
    "        candidate_movie_id = row['movieId']\n",
    "        \n",
    "        if candidate_movie_id in movie_map:\n",
    "            movie_matrix_index = movie_map[candidate_movie_id]\n",
    "            item_vec = item_factors[movie_matrix_index]\n",
    "            pred_rating = np.dot(user_vec, item_vec)\n",
    "            predictions.append((row['title'], pred_rating))\n",
    "        \n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [title for title, rating in predictions[:10]]\n",
    "\n",
    "def main():\n",
    "    print(\"--- 1. Loading Real Data ---\")\n",
    "    movies_df = pd.read_csv(\"/mnt/10EE4B76EE4B5360/College/pccoe/7th Sem/RS/RS-A2_A3_movie.csv\")\n",
    "    ratings_df = pd.read_csv(\"/mnt/10EE4B76EE4B5360/College/pccoe/7th Sem/RS/RS-A2_A3_Filtered_Ratings.csv\", nrows=RATINGS_SAMPLE_SIZE)\n",
    "\n",
    "    print(f\"Loaded {len(movies_df)} movies.\")\n",
    "    print(f\"Loaded a sample of {len(ratings_df)} ratings (up to {RATINGS_SAMPLE_SIZE}).\")\n",
    "    \n",
    "    print(\"\\n--- 2. Applying Filtering Logic ---\")\n",
    "    \n",
    "    movie_counts = ratings_df['movieId'].value_counts()\n",
    "    movies_to_keep = movie_counts[movie_counts >= MIN_MOVIE_RATINGS].index\n",
    "    ratings_f1 = ratings_df[ratings_df['movieId'].isin(movies_to_keep)]\n",
    "    print(f\"Ratings after (movie >= {MIN_MOVIE_RATINGS}): {len(ratings_f1)}\")\n",
    "\n",
    "    user_counts = ratings_f1['userId'].value_counts()\n",
    "    users_to_keep = user_counts[user_counts >= MIN_USER_RATINGS].index\n",
    "    ratings_f2 = ratings_f1[ratings_f1['userId'].isin(users_to_keep)]\n",
    "    print(f\"Ratings after (user >= {MIN_USER_RATINGS}): {len(ratings_f2)}\")\n",
    "\n",
    "    print(\"Applying rating cap (this may take a moment)...\")\n",
    "    ratings_f3 = ratings_f2.groupby('movieId').apply(cap_movie_ratings).reset_index(drop=True)\n",
    "    print(f\"Ratings after (movie <= {MAX_MOVIE_RATINGS}): {len(ratings_f3)}\")\n",
    "    \n",
    "    ratings_final_df = ratings_f3\n",
    "    \n",
    "    movies_filtered_df = movies_df[movies_df['movieId'].isin(ratings_final_df['movieId'].unique())]\n",
    "    \n",
    "    print(f\"\\nFinal movies in system: {len(movies_filtered_df)}\")\n",
    "    print(f\"Final ratings in system: {len(ratings_final_df)}\")\n",
    "    print(f\"Final users in system: {ratings_final_df['userId'].nunique()}\")\n",
    "    \n",
    "    print(\"\\n--- 3. Building Content-Based Filter (TF-IDF) ---\")\n",
    "    cosine_sim, content_indices, movies_indexed_df = get_content_filter(movies_filtered_df)\n",
    "    print(\"Content filter built.\")\n",
    "\n",
    "    print(\"\\n--- 4. Building Collaborative Ranker (sklearn TruncatedSVD) ---\")\n",
    "    svd, u_factors, i_factors, user_map, movie_map, final_user_list = get_collaborative_filter(ratings_final_df)\n",
    "    print(\"Collaborative ranker built.\")\n",
    "    \n",
    "    print(\"\\n--- 5. Getting Hybrid Recommendations ---\")\n",
    "    \n",
    "    TEST_USER_ID = final_user_list[0]\n",
    "    TEST_MOVIE = movies_indexed_df.iloc[0]['title']\n",
    "        \n",
    "    print(f\"\\nTarget User: {TEST_USER_ID}, Target Movie: {TEST_MOVIE}\")\n",
    "    \n",
    "    recommendations = get_hybrid_recommendations(\n",
    "        TEST_USER_ID, TEST_MOVIE, \n",
    "        movies_indexed_df, content_indices, cosine_sim,\n",
    "        svd, u_factors, i_factors, user_map, movie_map\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTop 10 Hybrid Recommendations:\")\n",
    "    for i, title in enumerate(recommendations):\n",
    "        print(f\"{i+1}. {title}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
